# Stock Sentiment Analysis V2 - Mermaid Diagrams
# This file contains all Mermaid diagram definitions for INDEX_V2.md

# =============================================================================
# Diagram 1: Complete System Architecture (Full Detail)
# =============================================================================

```mermaid
graph TB
    subgraph "User Interface Layer"
        UI[Streamlit Web UI<br/>- Stock Symbol Input<br/>- Data Loading<br/>- Visualization Tabs]
    end
    
    subgraph "Presentation Layer"
        INIT[Initialization Module<br/>- Settings Loading<br/>- Service Setup<br/>- Session State]
        SIDEBAR[Sidebar Component<br/>- Cache Controls<br/>- TTL Settings<br/>- Operation Summary]
        LOADER[Data Loader<br/>- Orchestration<br/>- Error Handling<br/>- Logging]
        TABS[Tabs Module<br/>- Overview<br/>- Price Analysis<br/>- News & Sentiment<br/>- Technical Analysis<br/>- AI Insights<br/>- Comparison]
    end
    
    subgraph "Application Services Layer"
        COLLECTOR[Data Collector Service<br/>- Multi-Source Collection<br/>- yfinance API<br/>- Alpha Vantage API<br/>- Finnhub API<br/>- Reddit API]
        SENTIMENT[Sentiment Analyzer<br/>- GPT-4 Integration<br/>- Few-Shot Learning<br/>- RAG Context<br/>- Parallel Processing]
        RAG[RAG Service<br/>- Embedding Generation<br/>- Query Expansion<br/>- Hybrid Search<br/>- Temporal Decay]
        CACHE[Cache Service<br/>- Redis Integration<br/>- TTL Management<br/>- Cache Statistics]
    end
    
    subgraph "Vector Database Layer"
        VECTOR_DB[Azure AI Search<br/>- HNSW Indexing<br/>- Vector Search<br/>- Keyword Search<br/>- Hybrid Search<br/>- OData Filtering]
        HNSW[HNSW Algorithm<br/>- Multi-Layer Graph<br/>- Log-time Search<br/>- 95%+ Recall]
    end
    
    subgraph "AI/ML Layer"
        GPT4[Azure OpenAI GPT-4<br/>- Sentiment Analysis<br/>- Temperature: 0.2<br/>- JSON Output]
        EMBEDDING[text-embedding-ada-002<br/>- 1536 Dimensions<br/>- Batch Processing<br/>- Semantic Search]
    end
    
    subgraph "Data Storage Layer"
        REDIS[(Redis Cache<br/>- Stock Data<br/>- News Articles<br/>- Sentiment Results<br/>- Embeddings Cache)]
        AZURE_SEARCH[(Azure AI Search Index<br/>- Article Vectors<br/>- Metadata<br/>- Timestamps)]
    end
    
    subgraph "External Data Sources"
        YFINANCE[yfinance API<br/>- Stock Prices<br/>- Company Info<br/>- News Articles]
        ALPHA_V[Alpha Vantage API<br/>- News Articles<br/>- Market Data]
        FINNHUB[Finnhub API<br/>- Company News<br/>- Market News]
        REDDIT_API[Reddit API<br/>- Social Posts<br/>- Community Sentiment]
    end
    
    subgraph "Algorithms & Math"
        COSINE[Cosine Similarity<br/>cos(θ) = (A·B)/(||A||×||B||)]
        RRF[Reciprocal Rank Fusion<br/>RRF = Σ(1/(k+rank))<br/>k=60]
        TEMP_DECAY[Temporal Decay<br/>decay = 1/(1+age/7)<br/>boost = score×(1+decay×0.2)]
        NORM[Sentiment Normalization<br/>norm = raw/sum<br/>net = pos - neg]
    end
    
    UI --> INIT
    INIT --> SIDEBAR
    INIT --> LOADER
    INIT --> TABS
    
    LOADER --> COLLECTOR
    LOADER --> RAG
    LOADER --> SENTIMENT
    LOADER --> CACHE
    
    COLLECTOR --> YFINANCE
    COLLECTOR --> ALPHA_V
    COLLECTOR --> FINNHUB
    COLLECTOR --> REDDIT_API
    COLLECTOR --> CACHE
    
    RAG --> EMBEDDING
    RAG --> VECTOR_DB
    RAG --> COSINE
    RAG --> RRF
    RAG --> TEMP_DECAY
    RAG --> CACHE
    
    VECTOR_DB --> HNSW
    VECTOR_DB --> AZURE_SEARCH
    
    SENTIMENT --> GPT4
    SENTIMENT --> RAG
    SENTIMENT --> NORM
    SENTIMENT --> CACHE
    
    CACHE --> REDIS
    
    EMBEDDING --> AZURE_SEARCH
    GPT4 --> AZURE_SEARCH
    
    style UI fill:#e1f5ff
    style VECTOR_DB fill:#fff4e1
    style GPT4 fill:#ffe1f5
    style EMBEDDING fill:#ffe1f5
    style COSINE fill:#e1ffe1
    style RRF fill:#e1ffe1
    style TEMP_DECAY fill:#e1ffe1
    style NORM fill:#e1ffe1
    style HNSW fill:#fff4e1
```

# =============================================================================
# Diagram 2: Detailed RAG Flow with Algorithms
# =============================================================================

```mermaid
sequenceDiagram
    participant User
    participant App as Streamlit App
    participant Collector as Data Collector
    participant RAG as RAG Service
    participant Embed as Embedding Model
    participant VectorDB as Azure AI Search
    participant Sentiment as Sentiment Analyzer
    participant GPT4 as GPT-4
    participant Cache as Redis Cache
    
    User->>App: Enter Stock Symbol (e.g., "AAPL")
    App->>Collector: collect_all_data("AAPL")
    
    Note over Collector: Multi-Source Collection
    Collector->>Collector: Fetch from yfinance
    Collector->>Collector: Fetch from Alpha Vantage (if enabled)
    Collector->>Collector: Fetch from Finnhub (if enabled)
    Collector->>Collector: Fetch from Reddit (if enabled)
    Collector->>Collector: Deduplicate articles
    Collector-->>App: Return articles list
    
    App->>RAG: store_articles_batch(articles, "AAPL")
    
    Note over RAG: Phase 1: Ingestion
    RAG->>RAG: Preprocess text (remove HTML, expand abbreviations)
    RAG->>Embed: get_embeddings_batch(texts, batch_size=100)
    Note over Embed: Batch Processing<br/>100 articles = 1 API call<br/>100× efficiency gain
    Embed-->>RAG: Return embeddings (1536 dims each)
    RAG->>VectorDB: batch_store_vectors(embeddings, metadata)
    Note over VectorDB: HNSW Indexing<br/>O(N log N) build<br/>O(log N) search
    VectorDB-->>RAG: Storage confirmed
    
    Note over App: For each article, analyze sentiment
    App->>Sentiment: analyze_sentiment(article_text, "AAPL")
    
    Note over Sentiment: Check Cache First
    Sentiment->>Cache: get_cached_sentiment(text_hash)
    Cache-->>Sentiment: Cache miss (first time)
    
    Note over Sentiment: Phase 2: RAG Retrieval
    Sentiment->>RAG: retrieve_relevant_context(query, "AAPL", top_k=3)
    
    Note over RAG: Query Expansion
    RAG->>RAG: Expand query with synonyms<br/>"earnings" → "earnings profits revenue"
    
    Note over RAG: Generate Query Embedding
    RAG->>Embed: get_embedding(expanded_query)
    Embed-->>RAG: Query vector (1536 dims)
    
    Note over RAG: Hybrid Search
    RAG->>VectorDB: Semantic Search (Vector)
    Note over VectorDB: Cosine Similarity<br/>cos(θ) = (A·B)/(||A||×||B||)
    VectorDB-->>RAG: Semantic results (top 10)
    
    RAG->>VectorDB: Keyword Search (Full-Text)
    Note over VectorDB: BM25 Algorithm
    VectorDB-->>RAG: Keyword results (top 10)
    
    Note over RAG: Reciprocal Rank Fusion
    RAG->>RAG: RRF_score = Σ(1/(k+rank))<br/>k=60, combine both results
    RAG->>RAG: Apply Temporal Decay<br/>decay = 1/(1+age_days/7)<br/>boost = score×(1+decay×0.2)
    RAG->>RAG: Filter by threshold (auto-adjust if needed)
    RAG-->>Sentiment: Top 3 relevant articles
    
    Note over Sentiment: Phase 3: Generation
    Sentiment->>Sentiment: Format RAG context
    Sentiment->>GPT4: analyze_with_context(text, context)
    Note over GPT4: Few-Shot Learning<br/>Temperature: 0.2<br/>JSON Output
    GPT4-->>Sentiment: Sentiment scores<br/>{"positive": 0.85, "negative": 0.05, "neutral": 0.10}
    
    Note over Sentiment: Normalize Scores
    Sentiment->>Sentiment: Normalize: score/sum<br/>Net: positive - negative
    Sentiment->>Cache: cache_sentiment(text_hash, scores, ttl)
    Sentiment-->>App: Return SentimentScores
    
    App->>App: Aggregate all sentiment scores
    App->>App: Calculate averages<br/>avg_pos = Σ(pos)/N<br/>net = avg_pos - avg_neg
    App->>User: Display results with visualizations
```

# =============================================================================
# Diagram 3: Hybrid Search Algorithm Flow
# =============================================================================

```mermaid
flowchart TD
    START([Query: "Apple earnings beat expectations"])
    
    START --> EXPAND[Query Expansion<br/>Add synonyms & symbol<br/>"earnings profits revenue AAPL"]
    
    EXPAND --> EMBED[Generate Query Embedding<br/>text-embedding-ada-002<br/>1536 dimensions]
    
    EMBED --> SEMANTIC[Semantic Search<br/>Vector Similarity]
    EMBED --> KEYWORD[Keyword Search<br/>Full-Text Match]
    
    SEMANTIC --> COSINE[Calculate Cosine Similarity<br/>cos(θ) = (A·B)/(||A||×||B||)<br/>For each article]
    
    COSINE --> SEM_RESULTS[Semantic Results<br/>Ranked by similarity<br/>0.0 - 1.0 scores]
    
    KEYWORD --> BM25[BM25 Scoring<br/>Keyword frequency<br/>Inverse document frequency]
    
    BM25 --> KEY_RESULTS[Keyword Results<br/>Ranked by BM25 score<br/>0 - 100 scores]
    
    SEM_RESULTS --> RRF[Reciprocal Rank Fusion<br/>RRF(d) = Σ(1/(k+rank_i(d)))<br/>k = 60]
    KEY_RESULTS --> RRF
    
    RRF --> COMBINED[Combined Results<br/>Articles appearing in both<br/>rank higher]
    
    COMBINED --> TEMP_DECAY[Temporal Decay<br/>decay = 1/(1+age_days/7)<br/>boosted = score×(1+decay×0.2)]
    
    TEMP_DECAY --> FILTER[Filter by Threshold<br/>Auto-adjust if too restrictive<br/>min_rrf_score ≥ 0.01]
    
    FILTER --> TOP_K[Select Top K<br/>K = 3 articles]
    
    TOP_K --> OUTPUT([Final Results<br/>3 most relevant articles<br/>with RRF scores])
    
    style SEMANTIC fill:#e1f5ff
    style KEYWORD fill:#ffe1f5
    style RRF fill:#e1ffe1
    style TEMP_DECAY fill:#fff4e1
    style COSINE fill:#e1ffe1
```

# =============================================================================
# Diagram 4: Data Flow Architecture
# =============================================================================

```mermaid
flowchart LR
    subgraph "Input"
        USER[User Input<br/>Stock Symbol: "AAPL"]
    end
    
    subgraph "Data Collection"
        YF[yfinance API<br/>Stock + News]
        AV[Alpha Vantage<br/>News API]
        FH[Finnhub<br/>News API]
        RD[Reddit<br/>Social Posts]
    end
    
    subgraph "Processing Pipeline"
        DEDUP[Deduplication<br/>URL + Title Similarity<br/>85% threshold]
        PREPROC[Preprocessing<br/>HTML Removal<br/>Abbreviation Expansion]
        EMBED_BATCH[Batch Embedding<br/>100 articles/batch<br/>text-embedding-ada-002]
    end
    
    subgraph "Storage"
        REDIS_CACHE[(Redis Cache<br/>- Stock Data: 1h TTL<br/>- News: 2h TTL<br/>- Sentiment: 24h TTL)]
        AZURE_INDEX[(Azure AI Search<br/>- Vector Index: HNSW<br/>- Metadata: OData filters<br/>- 10-100× faster)]
    end
    
    subgraph "RAG Retrieval"
        QUERY_EMBED[Query Embedding<br/>Cached if repeated]
        HYBRID[Hybrid Search<br/>Semantic + Keyword<br/>RRF Combination]
        DECAY[Temporal Decay<br/>Boost recent articles]
    end
    
    subgraph "Sentiment Analysis"
        CACHE_CHECK{Cache Hit?}
        GPT4_CALL[GPT-4 Analysis<br/>With RAG Context<br/>Few-Shot Learning]
        NORMALIZE[Normalize Scores<br/>Ensure sum = 1.0<br/>Calculate net sentiment]
    end
    
    subgraph "Output"
        AGGREGATE[Aggregation<br/>Average scores<br/>Net sentiment]
        VIZ[Visualization<br/>Charts & Graphs<br/>Streamlit UI]
    end
    
    USER --> YF
    USER --> AV
    USER --> FH
    USER --> RD
    
    YF --> DEDUP
    AV --> DEDUP
    FH --> DEDUP
    RD --> DEDUP
    
    DEDUP --> PREPROC
    PREPROC --> EMBED_BATCH
    EMBED_BATCH --> AZURE_INDEX
    EMBED_BATCH --> REDIS_CACHE
    
    USER --> CACHE_CHECK
    CACHE_CHECK -->|Miss| QUERY_EMBED
    CACHE_CHECK -->|Hit| AGGREGATE
    
    QUERY_EMBED --> HYBRID
    AZURE_INDEX --> HYBRID
    HYBRID --> DECAY
    DECAY --> GPT4_CALL
    
    GPT4_CALL --> NORMALIZE
    NORMALIZE --> REDIS_CACHE
    NORMALIZE --> AGGREGATE
    
    AGGREGATE --> VIZ
    
    style USER fill:#e1f5ff
    style AZURE_INDEX fill:#fff4e1
    style GPT4_CALL fill:#ffe1f5
    style VIZ fill:#e1ffe1
```

# =============================================================================
# Diagram 5: Caching Strategy Multi-Tier
# =============================================================================

```mermaid
graph TB
    subgraph "Request Flow"
        REQ[API Request]
    end
    
    subgraph "L1: Memory Cache"
        L1[In-Memory Dictionary<br/>Fastest: ~1ms<br/>Limited Size<br/>LRU Eviction]
    end
    
    subgraph "L2: Redis Cache"
        L2[Redis Cache<br/>Fast: ~5-10ms<br/>Persistent<br/>Shared Across Instances]
    end
    
    subgraph "Cache Types"
        STOCK_CACHE[Stock Data Cache<br/>TTL: 1 hour<br/>Key: stock:AAPL]
        NEWS_CACHE[News Cache<br/>TTL: 2 hours<br/>Key: news:AAPL]
        SENTIMENT_CACHE[Sentiment Cache<br/>TTL: 24h (configurable)<br/>Key: sentiment:hash<br/>Can be disabled]
        EMBED_CACHE[Embedding Cache<br/>TTL: 7 days<br/>Key: embedding:hash]
        QUERY_CACHE[Query Embedding Cache<br/>TTL: 24 hours<br/>Key: query_embedding:hash]
    end
    
    subgraph "External APIs"
        API[External API Call<br/>Slow: 200-2000ms<br/>Cost: $0.0001-$0.01]
    end
    
    REQ --> L1
    L1 -->|Miss| L2
    L1 -->|Hit| RETURN1[Return Cached<br/>~1ms]
    
    L2 --> STOCK_CACHE
    L2 --> NEWS_CACHE
    L2 --> SENTIMENT_CACHE
    L2 --> EMBED_CACHE
    L2 --> QUERY_CACHE
    
    STOCK_CACHE -->|Miss| API
    NEWS_CACHE -->|Miss| API
    SENTIMENT_CACHE -->|Miss| API
    EMBED_CACHE -->|Miss| API
    QUERY_CACHE -->|Miss| API
    
    API -->|Store| L2
    L2 -->|Store| L1
    API --> RETURN2[Return Fresh Data<br/>~200-2000ms]
    
    style L1 fill:#e1ffe1
    style L2 fill:#e1f5ff
    style API fill:#ffe1f5
    style RETURN1 fill:#e1ffe1
    style RETURN2 fill:#fff4e1
```

# =============================================================================
# Diagram 6: HNSW Vector Index Structure
# =============================================================================

```mermaid
graph TB
    subgraph "HNSW Multi-Layer Graph"
        subgraph "Layer 2 - Top (Sparse)"
            L2A[Article A]
            L2B[Article B]
            L2C[Article C]
            L2A --- L2B
            L2B --- L2C
        end
        
        subgraph "Layer 1 - Middle"
            L1D[Article D]
            L1E[Article E]
            L1F[Article F]
            L1G[Article G]
            L1D --- L1E
            L1E --- L1F
            L1F --- L1G
            L2A -.-> L1D
            L2B -.-> L1E
            L2C -.-> L1F
        end
        
        subgraph "Layer 0 - Bottom (All Articles)"
            L0H[Article H]
            L0I[Article I]
            L0J[Article J]
            L0K[Article K]
            L0L[Article L]
            L0M[Article M]
            L0N[Article N]
            L0H --- L0I
            L0I --- L0J
            L0J --- L0K
            L0K --- L0L
            L0L --- L0M
            L0M --- L0N
            L1D -.-> L0H
            L1E -.-> L0I
            L1F -.-> L0J
            L1G -.-> L0K
        end
    end
    
    subgraph "Search Process"
        QUERY[Query Vector<br/>1536 dimensions]
        QUERY --> START[Start at Top Layer]
        START --> NAVIGATE[Navigate Graph<br/>Find Nearest Neighbor]
        NAVIGATE --> DESCEND[Move Down Layer]
        DESCEND --> NAVIGATE
        DESCEND --> BOTTOM[Reach Bottom Layer]
        BOTTOM --> KNN[Return K Nearest<br/>K=3-10]
    end
    
    subgraph "Performance"
        BUILD[Build Time<br/>O(N log N)]
        SEARCH[Search Time<br/>O(log N) avg]
        RECALL[Recall Rate<br/>95%+ for top K]
    end
    
    style L2A fill:#e1f5ff
    style L1D fill:#e1ffe1
    style L0H fill:#fff4e1
    style QUERY fill:#ffe1f5
    style KNN fill:#e1ffe1
```

# =============================================================================
# Diagram 7: Component Interaction Detail
# =============================================================================

```mermaid
graph TB
    subgraph "Presentation Layer"
        APP[app.py<br/>Orchestrator]
        INIT[initialization.py<br/>- Settings<br/>- Services<br/>- Session State]
        SIDEBAR[sidebar.py<br/>- Controls<br/>- Summary Log]
        LOADER[data_loader.py<br/>- Data Loading<br/>- Error Handling]
        TABS[ tabs/<br/>- overview_tab<br/>- price_analysis_tab<br/>- news_sentiment_tab<br/>- technical_analysis_tab<br/>- ai_insights_tab<br/>- comparison_tab]
    end
    
    subgraph "Service Layer"
        COLLECTOR[collector.py<br/>Multi-Source Data]
        SENTIMENT[sentiment.py<br/>GPT-4 Analysis]
        RAG[rag.py<br/>RAG Service]
        CACHE[cache.py<br/>Redis Integration]
        VECTOR_DB[vector_db.py<br/>Azure AI Search]
    end
    
    subgraph "Configuration"
        SETTINGS[settings.py<br/>Pydantic Settings<br/>Environment Variables]
    end
    
    subgraph "Models"
        SENT_MODEL[sentiment.py<br/>SentimentScores<br/>SentimentResult]
        STOCK_MODEL[stock.py<br/>StockData<br/>NewsArticle]
    end
    
    APP --> INIT
    APP --> SIDEBAR
    APP --> LOADER
    APP --> TABS
    
    INIT --> SETTINGS
    INIT --> COLLECTOR
    INIT --> SENTIMENT
    INIT --> RAG
    INIT --> CACHE
    INIT --> VECTOR_DB
    
    LOADER --> COLLECTOR
    LOADER --> RAG
    LOADER --> SENTIMENT
    LOADER --> CACHE
    
    SENTIMENT --> RAG
    SENTIMENT --> CACHE
    SENTIMENT --> SENT_MODEL
    
    RAG --> VECTOR_DB
    RAG --> CACHE
    RAG --> EMBEDDING[Azure OpenAI<br/>Embeddings]
    
    VECTOR_DB --> AZURE_SEARCH[Azure AI Search<br/>Index]
    
    CACHE --> REDIS[(Redis)]
    
    COLLECTOR --> YFINANCE[yfinance]
    COLLECTOR --> ALPHA_V[Alpha Vantage]
    COLLECTOR --> FINNHUB[Finnhub]
    COLLECTOR --> REDDIT[Reddit]
    
    style APP fill:#e1f5ff
    style RAG fill:#fff4e1
    style VECTOR_DB fill:#fff4e1
    style SENTIMENT fill:#ffe1f5
```

# =============================================================================
# Diagram 8: Mathematical Algorithms Visualization
# =============================================================================

```mermaid
graph TB
    subgraph "Cosine Similarity"
        VEC1[Vector A<br/>1536 dimensions<br/>Article 1 embedding]
        VEC2[Vector B<br/>1536 dimensions<br/>Article 2 embedding]
        DOT[Dot Product<br/>A·B = Σ(A_i × B_i)]
        NORM1[||A|| = √(Σ(A_i²))]
        NORM2[||B|| = √(Σ(B_i²))]
        COSINE_FORMULA[cos(θ) = (A·B)/(||A||×||B||)]
        RESULT1[Similarity Score<br/>0.0 - 1.0]
        
        VEC1 --> DOT
        VEC2 --> DOT
        VEC1 --> NORM1
        VEC2 --> NORM2
        DOT --> COSINE_FORMULA
        NORM1 --> COSINE_FORMULA
        NORM2 --> COSINE_FORMULA
        COSINE_FORMULA --> RESULT1
    end
    
    subgraph "Reciprocal Rank Fusion"
        SEM_RANK[Semantic Rank<br/>Article at rank 1]
        KEY_RANK[Keyword Rank<br/>Article at rank 2]
        RRF_FORMULA[RRF = 1/(k+rank_1) + 1/(k+rank_2)<br/>k = 60]
        RRF_SCORE[Combined RRF Score<br/>0.0164 + 0.0161 = 0.0325]
        
        SEM_RANK --> RRF_FORMULA
        KEY_RANK --> RRF_FORMULA
        RRF_FORMULA --> RRF_SCORE
    end
    
    subgraph "Temporal Decay"
        AGE[Article Age<br/>3 days old]
        DECAY_DAYS[Decay Half-Life<br/>7 days]
        DECAY_FORMULA[decay = 1/(1+age/decay_days)<br/>decay = 1/(1+3/7) = 0.70]
        BOOST_FACTOR[Boost Factor<br/>0.2 (20%)]
        BOOST_FORMULA[boosted = score×(1+decay×0.2)<br/>boosted = 0.0318×1.14 = 0.0362]
        
        AGE --> DECAY_FORMULA
        DECAY_DAYS --> DECAY_FORMULA
        DECAY_FORMULA --> BOOST_FORMULA
        BOOST_FACTOR --> BOOST_FORMULA
    end
    
    subgraph "Sentiment Normalization"
        RAW[Raw Scores<br/>pos=0.85, neg=0.05, neu=0.10]
        SUM[Sum = 1.00<br/>Already normalized]
        NET[Net Sentiment<br/>pos - neg = 0.80]
        
        RAW --> SUM
        SUM --> NET
    end
    
    style COSINE_FORMULA fill:#e1ffe1
    style RRF_FORMULA fill:#e1ffe1
    style DECAY_FORMULA fill:#e1ffe1
    style NET fill:#e1ffe1
```

